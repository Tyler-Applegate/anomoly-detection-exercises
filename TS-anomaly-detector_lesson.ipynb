{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Anomaly Detector\n",
    "\n",
    "We will use a concept known as Bollinger Bands to discover when behavior changes from what is \"expected\" or normal. Bollinger Bands is a volatility indicator and commonly used in stock market trading. \n",
    "\n",
    "Scenario: Discover anomalies in number of web pages accessed in a day by a user. Is there a bot copying the curriculum? \n",
    "\n",
    "We will accomplish this by breaking down to the following tasks:\n",
    "\n",
    "1. acquire the data\n",
    "2. prepare the data\n",
    "3. make the analysis process (which we will discuss later) work over all users. \n",
    "4. Turn the analysis process and calculations into a function that can be used to loop through for each user. \n",
    "5. Test the function on a single user. \n",
    "6. Analyze by looping over all users. \n",
    "\n",
    "The analysis process will look like this, for each user: \n",
    "\n",
    "1. compute necessary metrics to arrive at the final metric, %b (percent-b).\n",
    "2. add user id to the dataframe that contains all the metrics, including %b. \n",
    "3. filter to rows where %b indicates anomaly (i.e. > 1)\n",
    "4. append rows of anomalies of new user to previous users' anomalous activity. \n",
    "\n",
    "Finally, we will do a quick sample of exploration of the anomalies. There is much more you can do! \n",
    "\n",
    "Your exercise will be to add comments, markdown, and docstrings to the code in this lesson. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Google Slide Presentation:     https://docs.google.com/presentation/d/1hLFy6cWmJ4-bVUNykEGvXWxHnCwYMuFlsU0qwzxLCw4/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Acquire**\n",
    "\n",
    "After doing some research, some experimentation of performing actions and watching the logs, we discovered what each of the fields represent. We then parse and name the fields accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>endpoint</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>source_ip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>/</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>97.105.19.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>java-ii</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>97.105.19.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>java-ii/object-oriented-programming</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>97.105.19.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>slides/object_oriented_programming</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>97.105.19.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>javascript-i/conditionals</td>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>97.105.19.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                             endpoint  user_id  cohort_id  \\\n",
       "0  2018-01-26                                    /        1        8.0   \n",
       "1  2018-01-26                              java-ii        1        8.0   \n",
       "2  2018-01-26  java-ii/object-oriented-programming        1        8.0   \n",
       "3  2018-01-26   slides/object_oriented_programming        1        8.0   \n",
       "4  2018-01-26            javascript-i/conditionals        2       22.0   \n",
       "\n",
       "      source_ip  \n",
       "0  97.105.19.61  \n",
       "1  97.105.19.61  \n",
       "2  97.105.19.61  \n",
       "3  97.105.19.61  \n",
       "4  97.105.19.61  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames = ['date', 'endpoint', 'user_id', 'cohort_id', 'source_ip']\n",
    "df = pd.read_csv(\"anonymized-curriculum-access-07-2021.txt\", \n",
    "                 sep=\"\\s\", \n",
    "                 header=None, \n",
    "                 names = colnames, \n",
    "                 usecols=[0, 2, 3, 4, 5])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.date = pd.to_datetime(df.date)\n",
    "df = df.set_index(df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample daily counts for number of page views\n",
    "\n",
    "pages = df['endpoint'].resample('d').count()\n",
    "pages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot pages\n",
    "pages.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No need to split because we are not modeling, we are using statistics to identify low probability cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponential Moving Average\n",
    "\n",
    "SMA time series are much less noisy than the time series of the original data points. \n",
    "The challenge with SMA, however, is that the values of SMA lag the original values. This means that changes in the trend are only seen with a delay (lag) of L time units. \n",
    "\n",
    "Exponential Moving Average (EMA) helps reduce the lag induced by the use of the SMA. It does this by putting more weight on more recent observations, while the SMA weights all observations equally.\n",
    "\n",
    "The EMA function looks like this: \n",
    "\n",
    "$EMA_{t}= \\alpha * (t_{0} - EMA_{t-1}) + EMA_{t-1}$\n",
    "\n",
    "Where: \n",
    "\n",
    "- M = Number of time periods, span of the window\n",
    "\n",
    "- $t_{0}$ = Latest value\n",
    "\n",
    "- $t-1$ = Previous value\n",
    "\n",
    "- $EMA_{t-1}$ = Exponential moving average of previous day. \n",
    "\n",
    "- The multiplier: $\\alpha = \\frac{2}{M+1}$\n",
    "\n",
    "However, we will use the pandas ewm (Exponential Weighted functions) to compute our EMA. \n",
    "So we just need to define the following: \n",
    "\n",
    "- M = `span` argument = number of time periods. We will try 7 days, 14 days, and 30 days. \n",
    "\n",
    "- Notice how there are no missing values. ewm() will use as many values are available to compute the mean. So if the span is 7 days, but it is on the first day of data available, the EMA will equal the first value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 day EMA\n",
    "ema_7d = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14 days EMA\n",
    "ema_14d = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 days EMA\n",
    "ema_30d = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90 days EMA\n",
    "ema_90d = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "ax.plot(pages.index, pages, label='Daily', alpha=.5)\n",
    "\n",
    "ax.plot(pages.index, ema_7d, label = '7-day EMA')\n",
    "ax.plot(pages.index, ema_14d, label = '14-day EMA')\n",
    "ax.plot(pages.index, ema_30d, label = '30-day EMA')\n",
    "ax.plot(pages.index, ema_90d, label = '30-day EMA')\n",
    "\n",
    "ax.legend(loc='best')\n",
    "ax.set_ylabel('Number of pages')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bollinger Bands and %b\n",
    "\n",
    "**Bollinger Bands**\n",
    "\n",
    "- a volatility indicator and commonly used in stock market trading. \n",
    "\n",
    "- Made up of 3 lines, the Upper Band (UB), the Lower Band (LB) and the Midband.  \n",
    "\n",
    "**Midband**\n",
    "\n",
    "- The Exponential Moving Average\n",
    "\n",
    "- `midband = train.ewm(span=30).mean()`\n",
    "\n",
    "**Upper & Lower Band**\n",
    "\n",
    "- UB/LB = Midband +/- stdev * K\n",
    "\n",
    "- `stdev = train.ewm(span=30).std()` \n",
    "\n",
    "- K = the number of standard deviations to go up and down from the EMA\n",
    "\n",
    "**%b, Percent Bandwidth**\n",
    "\n",
    "- Shows where the last value sits in relation to the bands\n",
    "\n",
    "- $\\%b = \\frac{last-LB}{UB-LB}$ \n",
    "\n",
    "- %b > 1 => point lies above UB\n",
    "\n",
    "- %b < 0 => point lies below LB\n",
    "\n",
    "- %b == .5 => point lies on the midband. \n",
    "\n",
    "**Bandwidth** \n",
    "\n",
    "- The width of the bands\n",
    "\n",
    "- $Bandwidth = \\frac{(UB-LB)}{Midband}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the window span\n",
    "span = 30\n",
    "\n",
    "# compute midband\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute exponential stdev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute upper and lower bands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat pages, midband, lb and ub to create a new df 'my_df'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "ax.plot(my_df.index, my_df.pages, label='Number of Pages')\n",
    "\n",
    "ax.plot(my_df.index, my_df.midband, label = '30-day EMA/midband')\n",
    "ax.plot(my_df.index, my_df.ub, label = 'Upper Band')\n",
    "ax.plot(my_df.index, my_df.lb, label = 'Lower Band')\n",
    "\n",
    "ax.legend(loc='best')\n",
    "ax.set_ylabel('Number of pages')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute %b\n",
    "\n",
    "$\\%b = \\frac{last-LB}{UB-LB}$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute pct_b for each point  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, where do we see anomalies? We will search for %b values > 1. We don't need to search for values < 0 because with this example, a low extreme is not something we are concerned about. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull it all together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. acquire\n",
    "2. prep with user\n",
    "3. compute features\n",
    "    - compute midband\n",
    "    - compute standard deviation\n",
    "    - compute upper & lower band\n",
    "    - create df with metrics\n",
    "    - compute %b\n",
    "    - add user_id to dataframe\n",
    "4. Plot\n",
    "5. search for anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquire(file_name, column_names):\n",
    "    return pd.read_csv(file_name, sep=\"\\s\", header=None, names=column_names, usecols=[0, 2, 3, 4, 5])\n",
    "\n",
    "def prep(df, user):\n",
    "    df = df[df.user_id == user]\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "    df = df.set_index(df.date)\n",
    "    pages = df['endpoint'].resample('d').count()\n",
    "    return pages\n",
    "\n",
    "def compute_pct_b(pages, span, weight, user):\n",
    "    midband = pages.ewm(span=span).mean()\n",
    "    stdev = pages.ewm(span=span).std()\n",
    "    ub = midband + stdev * weight\n",
    "    lb = midband - stdev * weight\n",
    "    bb = pd.concat([ub, lb], axis=1)\n",
    "    my_df = pd.concat([pages, midband, bb], axis=1)\n",
    "    my_df.columns = ['pages', 'midband', 'ub', 'lb']\n",
    "    my_df['pct_b'] = (my_df['pages'] - my_df['lb'])/(my_df['ub'] - my_df['lb'])\n",
    "    my_df['user_id'] = user\n",
    "    return my_df\n",
    "\n",
    "def plt_bands(my_df, user):\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    ax.plot(my_df.index, my_df.pages, label='Number of Pages, User: '+str(user))\n",
    "    ax.plot(my_df.index, my_df.midband, label = 'EMA/midband')\n",
    "    ax.plot(my_df.index, my_df.ub, label = 'Upper Band')\n",
    "    ax.plot(my_df.index, my_df.lb, label = 'Lower Band')\n",
    "    ax.legend(loc='best')\n",
    "    ax.set_ylabel('Number of Pages')\n",
    "    plt.show()\n",
    "    \n",
    "def find_anomalies(df, user, span, weight):\n",
    "    pages = prep(df, user)\n",
    "    my_df = compute_pct_b(pages, span, weight, user)\n",
    "#     plt_bands(my_df, user)\n",
    "    return my_df[my_df.pct_b > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>endpoint</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>source_ip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>/</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>97.105.19.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>java-ii</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>97.105.19.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>java-ii/object-oriented-programming</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>97.105.19.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>slides/object_oriented_programming</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>97.105.19.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>javascript-i/conditionals</td>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>97.105.19.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                             endpoint  user_id  cohort_id  \\\n",
       "0  2018-01-26                                    /        1        8.0   \n",
       "1  2018-01-26                              java-ii        1        8.0   \n",
       "2  2018-01-26  java-ii/object-oriented-programming        1        8.0   \n",
       "3  2018-01-26   slides/object_oriented_programming        1        8.0   \n",
       "4  2018-01-26            javascript-i/conditionals        2       22.0   \n",
       "\n",
       "      source_ip  \n",
       "0  97.105.19.61  \n",
       "1  97.105.19.61  \n",
       "2  97.105.19.61  \n",
       "3  97.105.19.61  \n",
       "4  97.105.19.61  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"anonymized-curriculum-access-07-2021.txt\"\n",
    "column_names = ['date', 'endpoint', 'user_id', 'cohort_id', 'source_ip']\n",
    "df = acquire(file_name, column_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on a single user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 341\n",
    "span = 30\n",
    "weight = 3\n",
    "\n",
    "anomalies = pd.DataFrame()\n",
    "user_df = find_anomalies(df, user, span, weight)\n",
    "anomalies = pd.concat([anomalies, user_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pages</th>\n",
       "      <th>midband</th>\n",
       "      <th>ub</th>\n",
       "      <th>lb</th>\n",
       "      <th>pct_b</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-03-03</th>\n",
       "      <td>272</td>\n",
       "      <td>24.721632</td>\n",
       "      <td>232.200343</td>\n",
       "      <td>-182.757078</td>\n",
       "      <td>1.095913</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-18</th>\n",
       "      <td>3</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>2.442380</td>\n",
       "      <td>-2.055283</td>\n",
       "      <td>1.123980</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-10</th>\n",
       "      <td>4</td>\n",
       "      <td>0.305768</td>\n",
       "      <td>3.479509</td>\n",
       "      <td>-2.867973</td>\n",
       "      <td>1.082000</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-21</th>\n",
       "      <td>109</td>\n",
       "      <td>7.250725</td>\n",
       "      <td>88.818626</td>\n",
       "      <td>-74.317176</td>\n",
       "      <td>1.123709</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-13</th>\n",
       "      <td>52</td>\n",
       "      <td>6.283047</td>\n",
       "      <td>45.711487</td>\n",
       "      <td>-33.145393</td>\n",
       "      <td>1.079746</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-03</th>\n",
       "      <td>11</td>\n",
       "      <td>0.991326</td>\n",
       "      <td>10.107234</td>\n",
       "      <td>-8.124582</td>\n",
       "      <td>1.048967</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-25</th>\n",
       "      <td>10</td>\n",
       "      <td>0.873729</td>\n",
       "      <td>9.489350</td>\n",
       "      <td>-7.741892</td>\n",
       "      <td>1.029635</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-09</th>\n",
       "      <td>10</td>\n",
       "      <td>0.659630</td>\n",
       "      <td>8.244463</td>\n",
       "      <td>-6.925203</td>\n",
       "      <td>1.115727</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pages    midband          ub          lb     pct_b  user_id\n",
       "date                                                                   \n",
       "2019-03-03    272  24.721632  232.200343 -182.757078  1.095913      341\n",
       "2020-02-18      3   0.193548    2.442380   -2.055283  1.123980      341\n",
       "2020-03-10      4   0.305768    3.479509   -2.867973  1.082000      341\n",
       "2020-04-21    109   7.250725   88.818626  -74.317176  1.123709      341\n",
       "2020-07-13     52   6.283047   45.711487  -33.145393  1.079746      341\n",
       "2020-10-03     11   0.991326   10.107234   -8.124582  1.048967      341\n",
       "2020-10-25     10   0.873729    9.489350   -7.741892  1.029635      341\n",
       "2021-02-09     10   0.659630    8.244463   -6.925203  1.115727      341"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through all users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "span = 30\n",
    "weight = 3.5\n",
    "anomalies = pd.DataFrame()\n",
    "for u in list(df.user_id.unique()):\n",
    "    user_df = find_anomalies(df, u, span, weight)\n",
    "    anomalies = pd.concat([anomalies, user_df], axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pages</th>\n",
       "      <th>midband</th>\n",
       "      <th>ub</th>\n",
       "      <th>lb</th>\n",
       "      <th>pct_b</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-29</th>\n",
       "      <td>44</td>\n",
       "      <td>3.623334</td>\n",
       "      <td>42.081344</td>\n",
       "      <td>-34.834677</td>\n",
       "      <td>1.024945</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-08</th>\n",
       "      <td>101</td>\n",
       "      <td>8.248768</td>\n",
       "      <td>96.507472</td>\n",
       "      <td>-80.009936</td>\n",
       "      <td>1.025451</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-15</th>\n",
       "      <td>9</td>\n",
       "      <td>0.581421</td>\n",
       "      <td>8.457414</td>\n",
       "      <td>-7.294571</td>\n",
       "      <td>1.034446</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-09</th>\n",
       "      <td>4</td>\n",
       "      <td>0.262470</td>\n",
       "      <td>3.802115</td>\n",
       "      <td>-3.277175</td>\n",
       "      <td>1.027953</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-06</th>\n",
       "      <td>2</td>\n",
       "      <td>0.129825</td>\n",
       "      <td>1.889712</td>\n",
       "      <td>-1.630061</td>\n",
       "      <td>1.031334</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-02</th>\n",
       "      <td>72</td>\n",
       "      <td>10.456225</td>\n",
       "      <td>71.377304</td>\n",
       "      <td>-50.464854</td>\n",
       "      <td>1.005111</td>\n",
       "      <td>925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-29</th>\n",
       "      <td>32</td>\n",
       "      <td>3.881578</td>\n",
       "      <td>31.571606</td>\n",
       "      <td>-23.808449</td>\n",
       "      <td>1.007736</td>\n",
       "      <td>929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-11</th>\n",
       "      <td>44</td>\n",
       "      <td>5.582783</td>\n",
       "      <td>43.858655</td>\n",
       "      <td>-32.693089</td>\n",
       "      <td>1.001846</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-08</th>\n",
       "      <td>4</td>\n",
       "      <td>0.261672</td>\n",
       "      <td>3.779670</td>\n",
       "      <td>-3.256327</td>\n",
       "      <td>1.031315</td>\n",
       "      <td>983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-17</th>\n",
       "      <td>12</td>\n",
       "      <td>0.976462</td>\n",
       "      <td>11.894672</td>\n",
       "      <td>-9.941747</td>\n",
       "      <td>1.004824</td>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1209 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pages    midband         ub         lb     pct_b  user_id\n",
       "date                                                                 \n",
       "2019-01-29     44   3.623334  42.081344 -34.834677  1.024945        1\n",
       "2019-07-08    101   8.248768  96.507472 -80.009936  1.025451        1\n",
       "2018-10-15      9   0.581421   8.457414  -7.294571  1.034446        3\n",
       "2019-01-09      4   0.262470   3.802115  -3.277175  1.027953        3\n",
       "2019-04-06      2   0.129825   1.889712  -1.630061  1.031334        3\n",
       "...           ...        ...        ...        ...       ...      ...\n",
       "2021-06-02     72  10.456225  71.377304 -50.464854  1.005111      925\n",
       "2021-06-29     32   3.881578  31.571606 -23.808449  1.007736      929\n",
       "2021-06-11     44   5.582783  43.858655 -32.693089  1.001846      961\n",
       "2021-07-08      4   0.261672   3.779670  -3.256327  1.031315      983\n",
       "2021-06-17     12   0.976462  11.894672  -9.941747  1.004824      986\n",
       "\n",
       "[1209 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at value counts for pages in anomalies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is worth investigating! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "**file name:** time_series_anomaly_detection.py or time_series_anomaly_detection.ipynb\n",
    "\n",
    "The dataset for these exercises lives in the Codeup Data Science MySQL Server. The database name is `curriculum_logs`.\n",
    "\n",
    "Go through the lesson commenting code, adding docstrings, and adding markdown to support what is happening. \n",
    "\n",
    "Bonus:\n",
    "\n",
    "Discover users who are accessing our curriculum pages way beyond the end of their codeup time. What would the dataframe look like? Use time series method for detecting anomalies, like exponential moving average with %b.\n",
    "\n",
    "Can you label students who are viewing both the web dev and data science curriculum?\n",
    "Can you label students by the program they are in? \n",
    "Can you label users by student vs. staff?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
